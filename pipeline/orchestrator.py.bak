"""
Orchestrator helpers for sensible startup ordering and health checks.

Provides:
- wait_for_kafka_bootstrap
- ensure_topics_exist
- wait_for_topic_messages
- wait_for_ksql_table_materialization
- wait_for_connect_connectors
- wait_for_mongo
- small helper retries/timeouts

Usage:
  from pipeline.orchestrator import Orchestrator
  o = Orchestrator(...)
  o.ensure_kafka_and_topics(...)
  o.wait_for_producer_messages(...)
  o.apply_ksql_and_wait(...)
  o.register_connectors_and_wait(...)
"""

import time
import logging
from typing import List, Optional
import requests
from kafka.admin import KafkaAdminClient, NewTopic
from kafka import KafkaConsumer, TopicPartition
from pymongo import MongoClient
from pymongo.errors import ServerSelectionTimeoutError

logger = logging.getLogger("pipeline.orchestrator")
logger.setLevel(logging.INFO)
ch = logging.StreamHandler()
ch.setFormatter(logging.Formatter("[%(asctime)s] [orch] %(message)s", "%H:%M:%S"))
logger.addHandler(ch)


class Orchestrator:
    def __init__(self, kafka_bootstrap: str = "kafka:9092", ksql_url: str = "http://localhost:8088",
                 mongo_url: str = "mongodb://mongodb:27017", check_interval: float = 2.0):
        self.kafka_bootstrap = kafka_bootstrap
        self.ksql_url = ksql_url.rstrip("/")
        self.mongo_url = mongo_url
        self.check_interval = check_interval

    # ---------------- Kafka checks ----------------
    def wait_for_kafka_bootstrap(self, timeout: int = 60) -> bool:
        """
        Wait until Kafka bootstrap responds to metadata requests.
        """
        logger.info(f"Waiting for Kafka at {self.kafka_bootstrap} (timeout {timeout}s)...")
        start = time.time()
        while time.time() - start < timeout:
            try:
                admin = KafkaAdminClient(bootstrap_servers=self.kafka_bootstrap, request_timeout_ms=5000)
                # list topics as a lightweight check
                _ = admin.list_topics(timeout=5)
                admin.close()
                logger.info("Kafka bootstrap reachable")
                return True
            except Exception as e:
                logger.info(f"Kafka not ready yet: {e}")
            time.sleep(self.check_interval)
        logger.error("Kafka bootstrap timed out")
        return False

    def ensure_topics_exist(self, topics: List[str], partitions: int = 1, replication_factor: int = 1,
                            create_if_missing: bool = True, timeout: int = 30) -> bool:
        """
        Ensure that topics exist on the broker. Optionally create missing topics.
        """
        logger.info(f"Ensuring topics exist: {topics}")
        try:
            admin = KafkaAdminClient(bootstrap_servers=self.kafka_bootstrap, request_timeout_ms=10000)
        except Exception as e:
            logger.error(f"Failed to create AdminClient: {e}")
            return False

        start = time.time()
        while time.time() - start < timeout:
            try:
                existing = set(admin.list_topics(timeout=5))
                missing = [t for t in topics if t not in existing]
                if not missing:
                    logger.info("All topics present")
                    admin.close()
                    return True
                if create_if_missing:
                    new_topics = []
                    for t in missing:
                        new_topics.append(NewTopic(name=t, num_partitions=partitions, replication_factor=replication_factor))
                    if new_topics:
                        try:
                            admin.create_topics(new_topics=new_topics, validate_only=False)
                            logger.info(f"Created topics: {missing}")
                        except Exception as e:
                            logger.info(f"Attempt to create topics error (will retry): {e}")
                else:
                    logger.info(f"Topics missing (and create_if_missing=False): {missing}")
            except Exception as e:
                logger.info(f"Error listing/creating topics: {e}")
            time.sleep(self.check_interval)
        admin.close()
        logger.error("ensure_topics_exist timed out")
        return False

    def wait_for_topic_messages(self, topic: str, min_messages: int = 1, partitions: Optional[List[int]] = None,
                                timeout: int = 30) -> bool:
        """
        Wait until a topic has at least `min_messages` total across partitions.
        Uses KafkaConsumer.end_offsets to check rapidly.
        """
        logger.info(f"Waiting for at least {min_messages} message(s) on topic {topic} (timeout {timeout}s)")
        start = time.time()
        try:
            consumer = KafkaConsumer(bootstrap_servers=self.kafka_bootstrap, enable_auto_commit=False)
        except Exception as e:
            logger.error(f"Could not create KafkaConsumer: {e}")
            return False

        while time.time() - start < timeout:
            try:
                partitions_list = partitions or [p.partition for p in consumer.partitions_for_topic(topic) and consumer.partitions_for_topic(topic)]
                # safe: if partitions_for_topic returns None (topic missing), handle gracefully
                pf = consumer.partitions_for_topic(topic)
                if not pf:
                    logger.info(f"Topic {topic} not visible to consumer yet.")
                    time.sleep(self.check_interval)
                    continue
                tps = [TopicPartition(topic, p) for p in sorted(list(pf))]
                end_offsets = consumer.end_offsets(tps, timeout=5)
                total = sum(end_offsets.get(tp, 0) for tp in tps)
                logger.info(f"Topic {topic} end offsets sum={total}")
                if total >= min_messages:
                    consumer.close()
                    logger.info(f"Topic {topic} has >= {min_messages} message(s)")
                    return True
            except Exception as e:
                logger.info(f"Error checking end_offsets: {e}")
            time.sleep(self.check_interval)
        consumer.close()
        logger.error(f"Timeout waiting for messages on {topic}")
        return False

    # ---------------- ksql checks ----------------
    def ksql_post(self, path: str, payload: dict, timeout: int = 10):
        url = f"{self.ksql_url.rstrip('/')}/{path.lstrip('/')}"
        headers = {"Content-Type": "application/vnd.ksql.v1+json; charset=utf-8"}
        resp = requests.post(url, json=payload, headers=headers, timeout=timeout)
        resp.raise_for_status()
        return resp.json()

    def wait_for_ksql_table_materialization(self, table_name: str, backing_topic_hint: Optional[str] = None,
                                           timeout: int = 60) -> bool:
        """
        Polls ksqlDB for table extended describe until the backing topic has non-zero end offsets or
        until ksql reports materialized state. This is a heuristic and version-dependent.
        """
        logger.info(f"Waiting for ksqlDB table {table_name} materialization (timeout {timeout}s)")
        start = time.time()
        while time.time() - start < timeout:
            try:
                # get describe extended - use /ksql endpoint with DESCRIBE EXTENDED
                payload = {"ksql": f"DESCRIBE EXTENDED {table_name};", "streamsProperties": {}}
                out = self.ksql_post("/ksql", payload, timeout=10)
                # out is usually a list; find parts that mention topic and offsets
                # We'll be conservative: if /ksql returns without error, then check backing topic if provided
                if backing_topic_hint:
                    # check end offsets of backing topic
                    if self.wait_for_topic_messages(backing_topic_hint, min_messages=1, timeout=10):
                        logger.info(f"Backing topic {backing_topic_hint} has data")
                        return True
                else:
                    # if DESCRIBE returned, assume good enough (but we still prefer backing data)
                    logger.info(f"DESCRIBE EXTENDED returned for {table_name}")
                    return True
            except requests.HTTPError as e:
                logger.info(f"DESCRIBE EXTENDED failed: {e}")
            except Exception as e:
                logger.info(f"ksql describe check error: {e}")
            time.sleep(self.check_interval)
        logger.error(f"Timeout waiting for ksql table {table_name} to materialize")
        return False

    # ---------------- connectors & Mongo checks ----------------
    def wait_for_connectors(self, connect_url: str = "http://connect:8083", connectors: Optional[List[str]] = None,
                            timeout: int = 30) -> bool:
        """
        Wait until the Connect cluster reports the connectors exist and are RUNNING.
        connectors is a list of connector names to expect.
        """
        logger.info(f"Waiting for connectors on {connect_url} (timeout {timeout}s)")
        start = time.time()
        while time.time() - start < timeout:
            try:
                r = requests.get(f"{connect_url}/connectors", timeout=5)
                r.raise_for_status()
                installed = r.json()
                logger.info(f"Connectors installed: {installed}")
                if connectors:
                    missing = [c for c in connectors if c not in installed]
                    if missing:
                        logger.info(f"Connectors missing: {missing}")
                        time.sleep(self.check_interval)
                        continue
                    # check status for each connector
                    all_ok = True
                    for c in connectors:
                        st = requests.get(f"{connect_url}/connectors/{c}/status", timeout=5).json()
                        state = st.get("connector", {}).get("state", "")
                        tasks = st.get("tasks", [])
                        if state != "RUNNING" or any(t.get("state") != "RUNNING" for t in tasks):
                            all_ok = False
                            logger.info(f"Connector {c} not running yet: {state} / tasks states {[t.get('state') for t in tasks]}")
                            break
                    if all_ok:
                        logger.info("All connectors running")
                        return True
                else:
                    # no connectors specified, returning that connect is reachable
                    logger.info("Connect reachable")
                    return True
            except Exception as e:
                logger.info(f"Connect not ready: {e}")
            time.sleep(self.check_interval)
        logger.error("Timeout waiting for connectors")
        return False

    def wait_for_mongo(self, timeout: int = 30) -> bool:
        logger.info(f"Waiting for MongoDB at {self.mongo_url} (timeout {timeout}s)")
        start = time.time()
        while time.time() - start < timeout:
            try:
                client = MongoClient(self.mongo_url, serverSelectionTimeoutMS=3000)
                client.server_info()  # will throw if not available
                client.close()
                logger.info("MongoDB reachable")
                return True
            except ServerSelectionTimeoutError as e:
                logger.info(f"Mongo not ready: {e}")
            except Exception as e:
                logger.info(f"Mongo check error: {e}")
            time.sleep(self.check_interval)
        logger.error("Timeout waiting for MongoDB")
        return False
